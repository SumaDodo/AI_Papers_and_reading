{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural network attention",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Attention mechanism is paying attention to certain parts when processing the data.   \n",
        "\n",
        "#### Example task: translate the sentence : ' le chat est noir' to english sentence - ' the cat is black'    \n",
        "\n",
        "- Here, there will be total of five time steps in translation [each word + end of sentence] and at each time step attention is applied by assigning weights to input words.\n",
        "- the more important words the higher weights will be applied.\n",
        "\n",
        "- the main reason for using attention mechanism is to conserve the information from the first encoder cell without the loss of information during the process of decoding. Thus to handle this, the attention weight is added to all encoder outputs.\n",
        "\n",
        "- *How important is the validity of the weights in attention mechanism?* - Normally, it is ok to set random values as the backpropogation gradient process takes care of correcting it during training."
      ],
      "metadata": {
        "id": "mG7v4uf4aj8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Luong attention**"
      ],
      "metadata": {
        "id": "IS47oaXbc71f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Calculating encoder hidden  state*"
      ],
      "metadata": {
        "id": "3fWMDaPedSEj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h5Ou0JecaU0b"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import dropout\n",
        "class Encoder_LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, n_layers = 1, drop_prob = 0):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
        "\n",
        "  def forward(self, inputs, hidden):\n",
        "    embedded = self.embedding(inputs)\n",
        "    output, hidden = self.lstm(embedded, hidden)\n",
        "    return output, hidden"
      ],
      "metadata": {
        "id": "rOadaGBAdLxp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating alignment score** - alignment scores are calculated using new decoder hidden state and the encoder hidden state.    \n",
        "In Luong attention, alignment score can be calculated in three different ways:  \n",
        "1. Dot function - multiplying hidden encoder and hidden decoder\n",
        "2. General function - similar to the dot function but weight matrix is added to the equation\n",
        "3. concat function - W2 * tanhn(W1(H(encoder) + H(decoder)))"
      ],
      "metadata": {
        "id": "S0dh6qWUgD-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loung_attention_layer(nn.Module):\n",
        "  def __init(self, method, hidden_size):\n",
        "    super(Loung_attention_layer, self).__init()\n",
        "    self.method = method\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    if self.method not in ['dot', 'general', 'concat']:\n",
        "      raise ValueError(self.method, 'is not the correct attention method')\n",
        "    if self.method == 'general':\n",
        "      self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
        "    elif self.method == 'concat':\n",
        "      self.attn = torch.nn.Linear(self.hidden_size*2, hidden_size)\n",
        "      self.weight = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "  def get_dot_score(self, hidden, encoder_outputs):\n",
        "    return torch.sum(hidden*encoder_outputs, dim = 2)\n",
        "\n",
        "  def get_general_score(self, hidden, encoder_outputs):\n",
        "    energy = self.attn(encoder_outputs)\n",
        "    return torch.sum(hiden * energy, dim = 2)\n",
        "\n",
        "  def get_concat_score(self, hidden, encoder_outputs):\n",
        "    concat = torch.cat((hidden.expand(encoder-outputs.size(0), -1, -1), encoder_outputs), dim=2)\n",
        "    energy = torch.tanh(self.attn(concat))\n",
        "    return torch.sum(self.weight*energy, dim=2)\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs):\n",
        "    if self.method == 'dot':\n",
        "      attn_energy = self.get_dot_score(hidden, encoder_outputs)\n",
        "    elif self.method == 'general':\n",
        "      attn_energy = self.get_general_score(hidden, encoder_outputs)\n",
        "    elif self.method == 'concat':\n",
        "      attn_energy = self.get_concat_score(hidden, encoder_outputs)\n",
        "\n",
        "    attn_enegry = attn_energy.t() #transpose\n",
        "    return F.softmax(attn_energy, dim=1).unsqueeze(1) #attn_energy is softmaxed to retun the weight corresponding to each encoder output"
      ],
      "metadata": {
        "id": "DaqMbU9WfL4a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Luong_Decoder(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, attention, n_layers=1, drop_prob=0.1):\n",
        "    super(LoungDecoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_prob = drop_prob\n",
        "\n",
        "    self.attention = attention\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.drop_prob)\n",
        "    self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "    self.classifier = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "  def forward(self, inputs, hidden, encoder_outputs):\n",
        "    embedded = self.embedding(inputs).view(1, 1, -1) #embed input words\n",
        "    embedded = self.dropout(embedded)\n",
        "\n",
        "    lstm_out, hidden = self.lstm(embedded, hidden) # new hidden state for decoder\n",
        "\n",
        "    alignment_scores = self.attention(lstm_out, encoder_outputs) #calculate alignment scores\n",
        "\n",
        "    attn_weights = F.softmax(alignment_scores.view(1, -1), dim=1)\n",
        "\n",
        "    context_vector = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs) #calculating context vector by multiplying attention weights with encoder utputs\n",
        "\n",
        "    output = torch.cat((lstm_out, context_vector), -1) #calcumating the final decoder outut by concatenating putput from LSTM with context vector\n",
        "\n",
        "    output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
        "\n",
        "    return output. hidden, attn_weights"
      ],
      "metadata": {
        "id": "ks3ZzjfVmARM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s6cRZNRMr7wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://www.kaggle.com/code/tientd95/understanding-attention-in-neural-network\n",
        "\n",
        "https://blog.floydhub.com/attention-mechanism/"
      ],
      "metadata": {
        "id": "cmbo4jw6r93o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OsLCl2J0sHGI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}